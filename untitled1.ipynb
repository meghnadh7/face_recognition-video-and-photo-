{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67d075-f4e5-4104-8b25-d62f025289e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80032aab-65c5-4fc8-b7f5-04438d15dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac6a8e-ee79-4ea3-bc0d-2d797523f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053f891-54b9-4bf9-9acc-7bf61d7a43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2614aab6-6280-4b31-ab39-615359432066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import face_recognition\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d050c7ff-ffdd-4e89-88d5-654e7aa9b0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facial encodings saved to 'encodings.pickle'\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def get_face_encodings(image_path):\n",
    "    # Load the image\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "    # Find all face locations in the image\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "\n",
    "    # Get facial encodings for all faces in the image\n",
    "    face_encodings = face_recognition.face_encodings(image, face_locations)\n",
    "\n",
    "    return face_encodings\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace 'path_to_images_directory' with the path to your directory containing images\n",
    "    images_directory = 'Desktop/,j,n,nn'\n",
    "\n",
    "    # Get a list of all image files in the directory\n",
    "    image_files = [f for f in os.listdir(images_directory) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    # Dictionary to store image filenames and corresponding facial encodings\n",
    "    encodings_dict = {}\n",
    "\n",
    "    for image_file in image_files:\n",
    "        # Construct the full path to each image file\n",
    "        image_path = os.path.join(images_directory, image_file)\n",
    "\n",
    "        # Get facial encodings for the current image\n",
    "        encodings = get_face_encodings(image_path)\n",
    "\n",
    "        # Store the facial encodings in the dictionary\n",
    "        encodings_dict[image_file] = encodings\n",
    "\n",
    "    # Save the encodings dictionary to a file using pickle\n",
    "    with open('encodings.pickle', 'wb') as file:\n",
    "        pickle.dump(encodings_dict, file)\n",
    "\n",
    "    print(\"Facial encodings saved to 'encodings.pickle'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9234d69-e6dc-4f67-b28d-4f4fbdb0972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Manually set parameters\n",
    "dataset_path = \"Desktop/,j,n,nn\"\n",
    "encodings_path = \"Desktop/encodings.pickle\"\n",
    "detection_method = \"cnn\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "\n",
    "# Manually set the dataset path\n",
    "dataset_path = \"Desktop/,j,n,nn\"\n",
    "\n",
    "# Get the paths to the input images in the dataset\n",
    "imagePaths = list(paths.list_images(dataset_path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming imagePaths, face_recognition, and other necessary modules are already defined\n",
    "\n",
    "# Initialize the list of known encodings and known names\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "# Loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # Extract the person name from the image path\n",
    "    print(f\"[INFO] Processing image {i + 1}/{len(imagePaths)}\")\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "    # Load the input image and convert it from BGR to RGB\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect the (x, y)-coordinates of the bounding boxes corresponding to each face in the input image\n",
    "    boxes = face_recognition.face_locations(rgb, model=detection_method)\n",
    "\n",
    "    # Compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "    # Loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        # Add each encoding + name to our set of known names and encodings\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "\n",
    "        # Display the image with bounding boxes in the Jupyter notebook\n",
    "        face_image = image.copy()\n",
    "        for (top, right, bottom, left) in boxes:\n",
    "            cv2.rectangle(face_image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "        # Display the image\n",
    "        plt.imshow(face_image)\n",
    "        plt.title(f\"Detected Face in {name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Serialize encodings and names\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "\n",
    "# Save the serialized data to a file\n",
    "with open(encodings_path, \"wb\") as file:\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "print(\"[INFO] Facial encodings and names serialized and saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab2bdfd-3528-408b-9084-e911879292dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] quantifying faces...\n"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt  # Importing Matplotlib for displaying images\n",
    "\n",
    "\n",
    "# Manually set the parameters\n",
    "dataset_path = \"Desktop/,j,n,nn\"\n",
    "encodings_path = \"Desktop/encodings.pickle\"\n",
    "detection_method = \"cnn\"\n",
    "\n",
    "# Your existing code (without argparse) continues from here...\n",
    "\n",
    "# Grab the paths to the input images in our dataset\n",
    "print(\"[INFO] quantifying faces...\")\n",
    "imagePaths = list(paths.list_images(dataset_path))\n",
    "\n",
    "# Initialize the list of known encodings and known names\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "# Continue with the rest of your script...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744996b3-04a2-4c26-924a-c36600fc261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38037ba5-667d-4ca8-b410-eeb198af8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Define a function to be called with the interact widget\n",
    "def set_dataset_path(dataset_path):\n",
    "    global imagePaths\n",
    "    imagePaths = list(paths.list_images(dataset_path))\n",
    "    print(\"[INFO] quantifying faces...\")\n",
    "\n",
    "# Create an interact widget for setting the dataset path\n",
    "interact(set_dataset_path, dataset_path=widgets.Text(value='Desktop/,j,n,nn', description='Dataset Path:'));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229fb87-7bcb-4192-9f17-a5aa59ec9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "# Assuming imagePaths, cv2, face_recognition, and os are already defined\n",
    "\n",
    "# loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # extract the person name from the image path\n",
    "    print(\"[INFO] processing image {}/{}\".format(i + 1, len(imagePaths)))\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "    # load the input image and convert it from BGR (OpenCV ordering)\n",
    "    # to dlib ordering (RGB)\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image in the Jupyter notebook\n",
    "    display(Image(filename=imagePath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97d2a5-7bbe-4811-833b-c4a2c2cd42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Manually set parameters\n",
    "encodings_path = \"Desktop/encodings.pickle\"\n",
    "\n",
    "# Serialize encodings and names\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "\n",
    "# Save the serialized data to a file\n",
    "with open(encodings_path, \"wb\") as file:\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "print(\"[INFO] Facial encodings and names serialized and saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeec85e-f624-4fea-b9b2-8c963c0e2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tryyyyyyyyyy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "from imutils import paths  # Import the paths module\n",
    "\n",
    "# Manually set parameters\n",
    "dataset_path = \"Desktop/,j,n,nn\"\n",
    "encodings_path = \"Desktop/encodings.pickle\"\n",
    "detection_method = \"cnn\"\n",
    "\n",
    "# Grab the paths to the input images in our dataset\n",
    "print(\"[INFO] quantifying faces...\")\n",
    "imagePaths = list(paths.list_images(dataset_path))\n",
    "\n",
    "# Initialize the list of known encodings and known names\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "# Loop over the image paths\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # Extract the person name from the image path\n",
    "    print(f\"[INFO] Processing image {i + 1}/{len(imagePaths)}\")\n",
    "    name = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "    # Load the input image and convert it from BGR to RGB\n",
    "    image = cv2.imread(imagePath)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect the (x, y)-coordinates of the bounding boxes corresponding to each face in the input image\n",
    "    boxes = face_recognition.face_locations(rgb, model=detection_method)\n",
    "\n",
    "    # Compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "    # Loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        # Add each encoding + name to our set of known names and encodings\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "\n",
    "        # Display the image with bounding boxes in the Jupyter notebook\n",
    "        face_image = image.copy()\n",
    "        for (top, right, bottom, left) in boxes:\n",
    "            cv2.rectangle(face_image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            \n",
    "            \n",
    "# Display the image\n",
    "        plt.imshow(face_image)\n",
    "        plt.title(f\"Detected Face in {name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc9810-f419-490e-8bc1-694beb4c57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Manually set parameters\n",
    "dataset_path = \"dataset\"\n",
    "encodings_path = \"encodings.pickle\"\n",
    "\n",
    "# Initialize the list of known encodings and known names\n",
    "knownEncodings = []\n",
    "knownNames = []\n",
    "\n",
    "# List all image files in the dataset directory\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Loop over the image files\n",
    "for i, image_file in enumerate(image_files):\n",
    "    # Construct the full path to each image file\n",
    "    image_path = os.path.join(dataset_path, image_file)\n",
    "\n",
    "    # Extract the person name from the image file name\n",
    "    name = os.path.splitext(image_file)[0]\n",
    "\n",
    "    # Load the input image and convert it from BGR to RGB\n",
    "    image = cv2.imread(image_path)\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect the (x, y)-coordinates of the bounding boxes corresponding to each face in the input image\n",
    "    boxes = face_recognition.face_locations(rgb, model=\"cnn\")\n",
    "\n",
    "    # Compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "    # Loop over the encodings\n",
    "    for encoding in encodings:\n",
    "        # Add each encoding + name to our set of known names and encodings\n",
    "        knownEncodings.append(encoding)\n",
    "        knownNames.append(name)\n",
    "\n",
    "# Serialize encodings and names\n",
    "data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "\n",
    "# Save the serialized data to a file\n",
    "with open(encodings_path, \"wb\") as file:\n",
    "    pickle.dump(data, file)\n",
    "\n",
    "print(\"[INFO] Facial encodings and names serialized and saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6cf67-4e13-472a-b612-fa300f30ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "# Manually set parameters\n",
    "encodings_path = \"encodings.pickle\"\n",
    "image_path = \"Downloads/images (14).jpg\"\n",
    "detection_method = \"cnn\"\n",
    "\n",
    "# Load the serialized database of facial encodings\n",
    "with open(encodings_path, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Load the input image\n",
    "image = cv2.imread(image_path)\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect the (x, y)-coordinates of the bounding boxes corresponding to each face in the input image\n",
    "boxes = face_recognition.face_locations(rgb, model=detection_method)\n",
    "\n",
    "# Compute the facial embedding for the face\n",
    "encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "# Loop over the facial embeddings\n",
    "for encoding in encodings:\n",
    "    # Compare the facial embedding with the ones in the database\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # Check if a match is found\n",
    "    if True in matches:\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "\n",
    "        # Count the number of times each name appears in the matches\n",
    "        for i in matchedIdxs:\n",
    "            name = data[\"names\"][i]\n",
    "            counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "        # Determine the most frequent name\n",
    "        name = max(counts, key=counts.get)\n",
    "\n",
    "    # Draw the bounding box and name on the image\n",
    "    for (top, right, bottom, left) in boxes:\n",
    "        cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d6c2e-9587-4f25-97a2-0fbc3a4ed7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "# Manually set parameters\n",
    "encodings_path = \"encodings.pickle\"\n",
    "image_path = \"Downloads/images (14).jpg\"\n",
    "detection_method = \"cnn\"\n",
    "\n",
    "# Load the known faces and embeddings\n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(encodings_path, \"rb\").read())\n",
    "\n",
    "# Load the input image and convert it from BGR to RGB\n",
    "image = cv2.imread(image_path)\n",
    "rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect the (x, y)-coordinates of the bounding boxes corresponding to each face in the input image\n",
    "print(\"[INFO] recognizing faces...\")\n",
    "boxes = face_recognition.face_locations(rgb, model=detection_method)\n",
    "\n",
    "# Compute the facial embeddings for each face\n",
    "encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "# Initialize the list of names for each face detected\n",
    "names = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329a4b36-5caf-4d30-a230-bd0837649785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after passing video or image as input if it doesn't recognise any face\n",
    "#it labels them as unknown, for that i am using this block of code\n",
    "# if it finds the face \n",
    "\n",
    "# Loop over the facial embeddings\n",
    "for encoding in encodings:\n",
    "    # Attempt to match each face in the input image to our known encodings\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    # Check if a match is found\n",
    "    if True in matches:\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "\n",
    "        # Count the number of times each name appears in the matches\n",
    "        for i in matchedIdxs:\n",
    "            name = data[\"names\"][i]\n",
    "            counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "        # Determine the most frequent name\n",
    "        name = max(counts, key=counts.get)\n",
    "\n",
    "    # Update the list of names\n",
    "    names.append(name)\n",
    "\n",
    "# Display the names associated with each face in the image\n",
    "for name in names:\n",
    "    print(f\"Detected Face: {name}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c615198-43f1-484b-90bc-94520a70fe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "matchedIdxs = [35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75]\n",
    "\n",
    "# Cell 2\n",
    "counts = {'ian': 40}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0411e1b-7888-462a-8864-33ab5c6073da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Assuming 'boxes' and 'names' are defined in the notebook environment\n",
    "# You should have the necessary imports and data loading above this cell\n",
    "\n",
    "# Assuming 'image' is also defined or loaded in the notebook environment\n",
    "\n",
    "for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "    # draw the predicted face name on the image\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "    y = top - 15 if top - 15 > 15 else top + 15\n",
    "    cv2.putText(image, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.75, (0, 255, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940ba2f-09d6-4c9d-a4db-113d5992db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'encodings.pickle' and 'examples/example_01.png' are in the same directory as the notebook\n",
    "\n",
    "# Cell 1\n",
    "!python recognize_faces_image.py --encodings encodings.pickle --image examples/example_01.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e80cde-2480-47d0-964c-e083c1cca4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils\n",
    "!pip install face_recognition\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import face_recognition\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Set your arguments as variables\n",
    "encodings_path = \"encodings.pickle\"\n",
    "output_path = \"encodings.pickle\"  # Set to None if you don't want an output video\n",
    "display_output = 1  # Set to 0 if you don't want to display the output frame to the screen\n",
    "detection_method = \"cnn\"  # Choose either 'hog' or 'cnn' for face detection\n",
    "\n",
    "# Load the serialized face encodings\n",
    "data = pickle.loads(open(encodings_path, \"rb\").read())\n",
    "\n",
    "# Initialize the video stream and wait for the camera to warm up\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Loop over frames from the video file stream\n",
    "while True:\n",
    "    # Grab the frame from the threaded video stream\n",
    "    frame = vs.read()\n",
    "\n",
    "    # Convert the input frame from BGR to RGB\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize the frame to have a width of 750px (just for display purposes)\n",
    "    frame = imutils.resize(frame, width=750)\n",
    "\n",
    "    # Detect the (x, y)-coordinates of the bounding boxes corresponding to each face in the input frame\n",
    "    boxes = face_recognition.face_locations(rgb, model=detection_method)\n",
    "\n",
    "    # Loop over the face locations and draw rectangles on the frame\n",
    "    for (top, right, bottom, left) in boxes:\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame to the screen\n",
    "    if display_output:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video stream and close OpenCV windows\n",
    "vs.stop()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86351a1d-f7aa-4957-a9b3-7b11f9dd9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face recognition in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7566c-14be-4da3-b6ec-2ad77dac35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imutils.video import VideoStream\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# Set your arguments as variables\n",
    "encodings_path = \"encodings.pickle\"\n",
    "\n",
    "# Load the known faces and embeddings\n",
    "print(\"[INFO] loading encodings...\")\n",
    "data = pickle.loads(open(encodings_path, \"rb\").read())\n",
    "\n",
    "# Initialize the video stream and wait for the camera to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "\n",
    "# Set up video writer (optional)\n",
    "output_path = \"Downloads/gold.mp4\"  # Set to None if you don't want an output video\n",
    "if output_path is not None:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, 20, (640, 480))\n",
    "\n",
    "# Loop over frames from the video stream\n",
    "while True:\n",
    "    # Grab the frame from the threaded video stream\n",
    "    frame = vs.read()\n",
    "\n",
    "    # Your processing logic here\n",
    "    # ...\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Write the frame to the output video file (if specified)\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "\n",
    "    # Break the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video stream and close OpenCV windows\n",
    "vs.stop()\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96886c99-4e47-4135-86b2-5f017fdf547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the facial embeddings\n",
    "for encoding in encodings:\n",
    "    # Attempt to match each face in the input image to our known encodings\n",
    "    matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "    name = \"Unknown\"\n",
    "    \n",
    "    # Check to see if we have found a match\n",
    "    if True in matches:\n",
    "        # Find the indexes of all matched faces then initialize a\n",
    "        # dictionary to count the total number of times each face\n",
    "        # was matched\n",
    "        matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "        counts = {}\n",
    "\n",
    "        # Loop over the matched indexes and maintain a count for\n",
    "        # each recognized face\n",
    "        for i in matchedIdxs:\n",
    "            name = data[\"names\"][i]\n",
    "            counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "        # Determine the recognized face with the largest number\n",
    "        # of votes (note: in the event of an unlikely tie Python\n",
    "        # will select the first entry in the dictionary)\n",
    "        name = max(counts, key=counts.get)\n",
    "\n",
    "    # Update the list of names\n",
    "    names.append(name)\n",
    "\n",
    "# Display the frame to the screen\n",
    "cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "# Break the loop if the 'q' key is pressed\n",
    "if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    break\n",
    "\n",
    "# Release the video stream and close OpenCV windows\n",
    "vs.stop()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e012e6c-26a4-4fd4-a994-879e89ed0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the recognized faces\n",
    "for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "    # Rescale the face coordinates\n",
    "    top = int(top * r)\n",
    "    right = int(right * r)\n",
    "    bottom = int(bottom * r)\n",
    "    left = int(left * r)\n",
    "\n",
    "    # Draw the predicted face name on the image\n",
    "    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "    y = top - 15 if top - 15 > 15 else top + 15\n",
    "    cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\n",
    "# Display the frame to the screen\n",
    "cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "# Break the loop if the 'q' key is pressed\n",
    "if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    break\n",
    "\n",
    "# Release the video stream and close OpenCV windows\n",
    "vs.stop()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcc779-b288-4e49-86cf-2ef32b01f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the video writer is None *AND* we are supposed to write\n",
    "# the output video to disk, initialize the writer\n",
    "if writer is None and output_path is not None:\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "    writer = cv2.VideoWriter(output_path, fourcc, 20, (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "# If the writer is not None, write the frame with recognized\n",
    "# faces to disk\n",
    "if writer is not None:\n",
    "    writer.write(frame)\n",
    "\n",
    "# Display the frame to the screen\n",
    "cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "# Break the loop if the 'q' key is pressed\n",
    "if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "    break\n",
    "\n",
    "# Release the video stream and close OpenCV windows\n",
    "vs.stop()\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bccc00-c499-4d47-b8df-a33e8a6b4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if we are supposed to display the output frame to the screen\n",
    "if display_output > 0:\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If the 'q' key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video stream and close OpenCV windows\n",
    "vs.stop()\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c079f9-8966-4e31-a8d2-a98f2a06479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n",
    "\n",
    "# Check to see if the video writer point needs to be released\n",
    "if writer is not None:\n",
    "    writer.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c792e-5cdd-4004-9926-7886cb58f640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
